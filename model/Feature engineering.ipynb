{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a9f33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6ee02",
   "metadata": {},
   "source": [
    "## 1. Retrieval of the pickled normalized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24a604d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = pd.read_pickle(\"../analysis/cvs_dataframe_normalized.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7c310",
   "metadata": {},
   "source": [
    "## 2. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a51329",
   "metadata": {},
   "source": [
    "We use the Scikit Lean vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28691f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', binary=False, decode_error='strict', \\\n",
    "encoding='utf-8', input='content', \\\n",
    "lowercase=True, max_df=1.0, max_features=None, min_df=1, \\\n",
    "ngram_range=(1, 1), preprocessor=None, stop_words=None, \\\n",
    "strip_accents=None, token_pattern='(?u)\\\\b[^\\\\d\\\\W]{2,}\\\\b',\n",
    "tokenizer=None, vocabulary=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c33fa32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(token_pattern=&#x27;(?u)\\\\b[^\\\\d\\\\W]{2,}\\\\b&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(token_pattern=&#x27;(?u)\\\\b[^\\\\d\\\\W]{2,}\\\\b&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(token_pattern='(?u)\\\\b[^\\\\d\\\\W]{2,}\\\\b')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(df_normalized[\"no_stopwords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41b44fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_cv = cv.transform(df_normalized[\"no_stopwords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2694c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1468, 37541)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt_cv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad97964",
   "metadata": {},
   "source": [
    "## 3. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51d8d664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1458</th>\n",
       "      <th>1459</th>\n",
       "      <th>1460</th>\n",
       "      <th>1461</th>\n",
       "      <th>1462</th>\n",
       "      <th>1463</th>\n",
       "      <th>1464</th>\n",
       "      <th>1465</th>\n",
       "      <th>1466</th>\n",
       "      <th>1467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298074</td>\n",
       "      <td>0.335854</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.266147</td>\n",
       "      <td>0.303577</td>\n",
       "      <td>0.310827</td>\n",
       "      <td>0.566764</td>\n",
       "      <td>0.179118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598634</td>\n",
       "      <td>0.303778</td>\n",
       "      <td>0.170447</td>\n",
       "      <td>0.162174</td>\n",
       "      <td>0.218598</td>\n",
       "      <td>0.239884</td>\n",
       "      <td>0.140732</td>\n",
       "      <td>0.259555</td>\n",
       "      <td>0.305388</td>\n",
       "      <td>0.409926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177055</td>\n",
       "      <td>0.181642</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.160715</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>0.174581</td>\n",
       "      <td>0.347288</td>\n",
       "      <td>0.104139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400575</td>\n",
       "      <td>0.248123</td>\n",
       "      <td>0.117146</td>\n",
       "      <td>0.143897</td>\n",
       "      <td>0.170492</td>\n",
       "      <td>0.179439</td>\n",
       "      <td>0.149619</td>\n",
       "      <td>0.181332</td>\n",
       "      <td>0.206230</td>\n",
       "      <td>0.223962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.335854</td>\n",
       "      <td>0.177055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116041</td>\n",
       "      <td>0.190801</td>\n",
       "      <td>0.289490</td>\n",
       "      <td>0.283694</td>\n",
       "      <td>0.307405</td>\n",
       "      <td>0.398697</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512819</td>\n",
       "      <td>0.481551</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>0.406555</td>\n",
       "      <td>0.342361</td>\n",
       "      <td>0.285292</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.211235</td>\n",
       "      <td>0.404495</td>\n",
       "      <td>0.624232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.181642</td>\n",
       "      <td>0.116041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216349</td>\n",
       "      <td>0.180174</td>\n",
       "      <td>0.163666</td>\n",
       "      <td>0.106496</td>\n",
       "      <td>0.232936</td>\n",
       "      <td>0.199342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308515</td>\n",
       "      <td>0.158592</td>\n",
       "      <td>0.125360</td>\n",
       "      <td>0.106168</td>\n",
       "      <td>0.178392</td>\n",
       "      <td>0.133697</td>\n",
       "      <td>0.232887</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.120199</td>\n",
       "      <td>0.181448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.190801</td>\n",
       "      <td>0.216349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>0.260699</td>\n",
       "      <td>0.171459</td>\n",
       "      <td>0.169161</td>\n",
       "      <td>0.304203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210223</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.105704</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.409898</td>\n",
       "      <td>0.099738</td>\n",
       "      <td>0.252828</td>\n",
       "      <td>0.195572</td>\n",
       "      <td>0.251753</td>\n",
       "      <td>0.201822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.266147</td>\n",
       "      <td>0.160715</td>\n",
       "      <td>0.289490</td>\n",
       "      <td>0.180174</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258590</td>\n",
       "      <td>0.217339</td>\n",
       "      <td>0.312830</td>\n",
       "      <td>0.288196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324966</td>\n",
       "      <td>0.252893</td>\n",
       "      <td>0.157438</td>\n",
       "      <td>0.266864</td>\n",
       "      <td>0.383036</td>\n",
       "      <td>0.199504</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>0.220611</td>\n",
       "      <td>0.343652</td>\n",
       "      <td>0.255767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.303577</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>0.283694</td>\n",
       "      <td>0.163666</td>\n",
       "      <td>0.260699</td>\n",
       "      <td>0.258590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196631</td>\n",
       "      <td>0.337277</td>\n",
       "      <td>0.246131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341940</td>\n",
       "      <td>0.306517</td>\n",
       "      <td>0.118072</td>\n",
       "      <td>0.185706</td>\n",
       "      <td>0.293371</td>\n",
       "      <td>0.179004</td>\n",
       "      <td>0.212385</td>\n",
       "      <td>0.245241</td>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.309087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.310827</td>\n",
       "      <td>0.174581</td>\n",
       "      <td>0.307405</td>\n",
       "      <td>0.106496</td>\n",
       "      <td>0.171459</td>\n",
       "      <td>0.217339</td>\n",
       "      <td>0.196631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338769</td>\n",
       "      <td>0.191791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383836</td>\n",
       "      <td>0.274102</td>\n",
       "      <td>0.099999</td>\n",
       "      <td>0.275852</td>\n",
       "      <td>0.239486</td>\n",
       "      <td>0.328765</td>\n",
       "      <td>0.215225</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.273617</td>\n",
       "      <td>0.283459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.566764</td>\n",
       "      <td>0.347288</td>\n",
       "      <td>0.398697</td>\n",
       "      <td>0.232936</td>\n",
       "      <td>0.169161</td>\n",
       "      <td>0.312830</td>\n",
       "      <td>0.337277</td>\n",
       "      <td>0.338769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664261</td>\n",
       "      <td>0.413338</td>\n",
       "      <td>0.172847</td>\n",
       "      <td>0.245617</td>\n",
       "      <td>0.250523</td>\n",
       "      <td>0.310650</td>\n",
       "      <td>0.166499</td>\n",
       "      <td>0.267786</td>\n",
       "      <td>0.360985</td>\n",
       "      <td>0.467658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.179118</td>\n",
       "      <td>0.104139</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.199342</td>\n",
       "      <td>0.304203</td>\n",
       "      <td>0.288196</td>\n",
       "      <td>0.246131</td>\n",
       "      <td>0.191791</td>\n",
       "      <td>0.204992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318288</td>\n",
       "      <td>0.302296</td>\n",
       "      <td>0.135350</td>\n",
       "      <td>0.253737</td>\n",
       "      <td>0.407128</td>\n",
       "      <td>0.180928</td>\n",
       "      <td>0.263420</td>\n",
       "      <td>0.161303</td>\n",
       "      <td>0.260783</td>\n",
       "      <td>0.287734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1468 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  1.000000  0.298074  0.335854  0.218218  0.144781  0.266147  0.303577   \n",
       "1  0.298074  1.000000  0.177055  0.181642  0.105528  0.160715  0.210404   \n",
       "2  0.335854  0.177055  1.000000  0.116041  0.190801  0.289490  0.283694   \n",
       "3  0.218218  0.181642  0.116041  1.000000  0.216349  0.180174  0.163666   \n",
       "4  0.144781  0.105528  0.190801  0.216349  1.000000  0.300049  0.260699   \n",
       "5  0.266147  0.160715  0.289490  0.180174  0.300049  1.000000  0.258590   \n",
       "6  0.303577  0.210404  0.283694  0.163666  0.260699  0.258590  1.000000   \n",
       "7  0.310827  0.174581  0.307405  0.106496  0.171459  0.217339  0.196631   \n",
       "8  0.566764  0.347288  0.398697  0.232936  0.169161  0.312830  0.337277   \n",
       "9  0.179118  0.104139  0.350608  0.199342  0.304203  0.288196  0.246131   \n",
       "\n",
       "       7         8         9     ...      1458      1459      1460      1461  \\\n",
       "0  0.310827  0.566764  0.179118  ...  0.598634  0.303778  0.170447  0.162174   \n",
       "1  0.174581  0.347288  0.104139  ...  0.400575  0.248123  0.117146  0.143897   \n",
       "2  0.307405  0.398697  0.350608  ...  0.512819  0.481551  0.092877  0.406555   \n",
       "3  0.106496  0.232936  0.199342  ...  0.308515  0.158592  0.125360  0.106168   \n",
       "4  0.171459  0.169161  0.304203  ...  0.210223  0.169014  0.105704  0.111087   \n",
       "5  0.217339  0.312830  0.288196  ...  0.324966  0.252893  0.157438  0.266864   \n",
       "6  0.196631  0.337277  0.246131  ...  0.341940  0.306517  0.118072  0.185706   \n",
       "7  1.000000  0.338769  0.191791  ...  0.383836  0.274102  0.099999  0.275852   \n",
       "8  0.338769  1.000000  0.204992  ...  0.664261  0.413338  0.172847  0.245617   \n",
       "9  0.191791  0.204992  1.000000  ...  0.318288  0.302296  0.135350  0.253737   \n",
       "\n",
       "       1462      1463      1464      1465      1466      1467  \n",
       "0  0.218598  0.239884  0.140732  0.259555  0.305388  0.409926  \n",
       "1  0.170492  0.179439  0.149619  0.181332  0.206230  0.223962  \n",
       "2  0.342361  0.285292  0.198526  0.211235  0.404495  0.624232  \n",
       "3  0.178392  0.133697  0.232887  0.113771  0.120199  0.181448  \n",
       "4  0.409898  0.099738  0.252828  0.195572  0.251753  0.201822  \n",
       "5  0.383036  0.199504  0.224077  0.220611  0.343652  0.255767  \n",
       "6  0.293371  0.179004  0.212385  0.245241  0.288678  0.309087  \n",
       "7  0.239486  0.328765  0.215225  0.188353  0.273617  0.283459  \n",
       "8  0.250523  0.310650  0.166499  0.267786  0.360985  0.467658  \n",
       "9  0.407128  0.180928  0.263420  0.161303  0.260783  0.287734  \n",
       "\n",
       "[10 rows x 1468 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_sim = pd.DataFrame(cosine_similarity(vt_cv, vt_cv), dtype='float')\n",
    "df_cos_sim.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed772221",
   "metadata": {},
   "source": [
    "We filter the values < 0.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8fabf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cos_sim_s = (df_cos_sim >= 0.4).stack()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc75f8",
   "metadata": {},
   "source": [
    "And create a list of coordinates (document_a_id, document_b_id), removing duples and tuples (document_b_id, document_a_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87cdf3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [*df_cos_sim_s[df_cos_sim_s].index]\n",
    "coord_undupled = [el for el in coord_undupled if el[0] < el[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c7bb9",
   "metadata": {},
   "source": [
    "We map this list to a list of tuples of statuses of the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2f43d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_list = [(df_normalized.loc[coord_a].status, df_normalized.loc[coord_b].status) for (coord_a, coord_b) in coord_undupled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fd7a2",
   "metadata": {},
   "source": [
    "And count the number of different tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78f301ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('bad', 'bad'): 64577, ('bad', 'good'): 6294, ('good', 'bad'): 6086, ('good', 'good'): 3703})\n"
     ]
    }
   ],
   "source": [
    "count_status = Counter(status_list)\n",
    "print(count_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1941a",
   "metadata": {},
   "source": [
    "The difference in favor of the ('bad', 'bad') tuples is striking. Fake CVs show more similarities among them than legitimate to fake documents or among legitimate ones. This points to a pattern in the vocabulary used in the fake documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a187b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
